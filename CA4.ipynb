{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data = pd.read_csv('train.csv', index_col=0)\n",
    "Test_data = pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shapes is 11543 rows and 15 columns \n",
    "\n",
    "\n",
    "\n",
    "df = Training_data.copy()\n",
    "missing_valuesc = df.loc[df.Bathroom.isna() == True]\n",
    "missing_values= df.isna().sum()\n",
    "# We have that a lot of the nummerical values in the year has nan values the number is 4572\n",
    "# As data cleaning goes this is too many values to be removing from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4370\n",
       "1    2040\n",
       "2     457\n",
       "Name: Price class, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis=0)\n",
    "\n",
    "year_unique_values = pd.unique(df.YearBuilt)\n",
    "year_unique_values = np.sort([x for x in year_unique_values if pd.isnull(x) == False])\n",
    "# Checking the unique values for year to try to find a way of cleaning the data.\n",
    "place_unique = pd.unique(df.Regionname)\n",
    "df['Price class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Removing all nan values, and removing Latitude and longtitude. No one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5801, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Removing all nan values and apply a standard one hot encoding to all the other values with catigorical values \n",
    "df1 = Training_data.copy()\n",
    "df1 = df1.dropna(axis=0)\n",
    "df1 = df1.replace(to_replace= [\n",
    "    'Eastern Metropolitan',\n",
    "    'Northern Metropolitan',\n",
    "    'Southern Metropolitan',\n",
    "    'Western Metropolitan',\n",
    "    'South-Eastern Metropolitan',\n",
    "    'Eastern Victoria',\n",
    "    'Northern Victoria',\n",
    "    'Western Victoria'], \n",
    "    value = [0,0,0,0,0,1,1,1])\n",
    "df1 = df1.replace(to_replace= ['h','u','t'],\n",
    "                value= [1,0,0] )\n",
    "df1 = df1.replace(to_replace= ['S','SP','PI','VB','SA'], value= [1,1,0,0,0])\n",
    "df1 = df1.drop(['Lattitude','Longtitude'], axis=1)\n",
    "df1 = df1[df1.Landsize != 0.0]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.iloc[:,:-1].copy()\n",
    "y = df1.iloc[:,-1].copy()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=100, stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8363479758828596 0.9997844827586206\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                        n_estimators=500, \n",
    "                                        random_state= 100,\n",
    "                                        n_jobs=-1)\n",
    "forest.fit(X_train, y_train)\n",
    "FTrain = forest.score(X_train, y_train)\n",
    "FTest  = forest.score(X_test, y_test)\n",
    "\n",
    "print(FTest,FTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_xtrain = X\n",
    "forest_ytrain = y\n",
    "forest_test = Test_data\n",
    "\n",
    "forest_test = forest_test.replace(to_replace= [\n",
    "    'Eastern Metropolitan',\n",
    "    'Northern Metropolitan',\n",
    "    'Southern Metropolitan',\n",
    "    'Western Metropolitan',\n",
    "    'South-Eastern Metropolitan',\n",
    "    'Eastern Victoria',\n",
    "    'Northern Victoria',\n",
    "    'Western Victoria'], \n",
    "    value = [0,0,0,0,0,1,1,1])\n",
    "forest_test = forest_test.replace(to_replace= ['h','u','t'],\n",
    "                value= [1,0,0] )\n",
    "forest_test = forest_test.replace(to_replace= ['S','SP','PI','VB','SA'], value= [1,1,0,0,0])\n",
    "forest_test = forest_test.drop(['Lattitude','Longtitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                n_estimators=500,\n",
    "                                random_state= 100,\n",
    "                                n_jobs=-1)\n",
    "forest.fit(forest_xtrain, forest_ytrain)\n",
    "\n",
    "forest_target_predictions = forest.predict(forest_test)\n",
    "output = pd.DataFrame({'index': forest_test.index,'Price class': forest_target_predictions})\n",
    "output.to_csv('CA4_submission_forest',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods for data cleaning \n",
    "\n",
    "# 2) removing all nan values and finding a way of using the target as an indicator for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Removing all nan values and apply a standard one hot encoding to all the other values with catigorical values \n",
    "df2 = Training_data.copy()\n",
    "df2 = df2.drop('YearBuilt',axis=1)\n",
    "df2 = df2.dropna(axis = 0)\n",
    "df2 = df2.replace(to_replace= [\n",
    "    'Eastern Metropolitan',\n",
    "    'Northern Metropolitan',\n",
    "    'Southern Metropolitan',\n",
    "    'Western Metropolitan',\n",
    "    'South-Eastern Metropolitan',\n",
    "    'Eastern Victoria',\n",
    "    'Northern Victoria',\n",
    "    'Western Victoria'], \n",
    "    value = [0,0,0,0,0,1,1,1])\n",
    "df2 = df2.replace(to_replace= ['h','u','t'],\n",
    "                value= [1,0,2] )\n",
    "df2 = df2.replace(to_replace= ['S','SP','PI','VB','SA'], value= [1,1,0,0,0])\n",
    "#df2 = df2.drop(['Lattitude','Longtitude'], axis=1)\n",
    "df2 = df2[df2.Landsize != 0.0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df2.iloc[:,:-1].copy()\n",
    "y1 = df2.iloc[:,-1].copy()\n",
    "X1_train,X1_test,y1_train,y1_test = train_test_split(X1,y1,test_size=0.3,random_state=100, stratify= y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8504609081597815 1.0\n"
     ]
    }
   ],
   "source": [
    "forest1 = RandomForestClassifier(criterion='gini',\n",
    "                                        n_estimators=1000, \n",
    "                                        random_state= 100,\n",
    "                                        n_jobs=-1)\n",
    "forest1.fit(X1_train, y1_train)\n",
    "FTrain1 = forest1.score(X1_train, y1_train)\n",
    "FTest1  = forest1.score(X1_test, y1_test)\n",
    "\n",
    "print(FTest1,FTrain1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230, 13) (9761, 13)\n"
     ]
    }
   ],
   "source": [
    "forest1_xtrain = X1\n",
    "forest1_ytrain = y1\n",
    "forest_test1 = Test_data\n",
    "forest_test1 = forest_test1.drop('YearBuilt',axis=1)\n",
    "\n",
    "forest_test1 = forest_test1.replace(to_replace= [\n",
    "    'Eastern Metropolitan',\n",
    "    'Northern Metropolitan',\n",
    "    'Southern Metropolitan',\n",
    "    'Western Metropolitan',\n",
    "    'South-Eastern Metropolitan',\n",
    "    'Eastern Victoria',\n",
    "    'Northern Victoria',\n",
    "    'Western Victoria'], \n",
    "    value = [0,0,0,0,0,1,1,1])\n",
    "forest_test1 = forest_test1.replace(to_replace= ['h','u','t'],\n",
    "                value= [1,0,2] )\n",
    "forest_test1 = forest_test1.replace(to_replace= ['S','SP','PI','VB','SA'], value= [1,1,0,0,0])\n",
    "\n",
    "print(forest_test1.shape,X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest1 = RandomForestClassifier(criterion='gini',\n",
    "                                n_estimators=1000,\n",
    "                                random_state= 100,\n",
    "                                n_jobs=-1)\n",
    "forest1.fit(forest1_xtrain, forest1_ytrain)\n",
    "\n",
    "forest1_target_predictions = forest1.predict(forest_test1)\n",
    "output = pd.DataFrame({'index': forest_test1.index,'Price class': forest1_target_predictions})\n",
    "output.to_csv('CA4_submission_forest1',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "      <th>Price class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7570.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>3189.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2555.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.4</td>\n",
       "      <td>3107.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5420.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11918.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3072.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14577.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms  Type  Method  Distance  Postcode  Bedrooms  Bathroom  Car  Landsize  \\\n",
       "0      4     1       0       6.4    3011.0       3.0       1.0  2.0     411.0   \n",
       "1      4     1       0      14.6    3189.0       4.0       1.0  2.0     638.0   \n",
       "2      5     1       2      12.4    3107.0       5.0       4.0  2.0     968.0   \n",
       "3      3     1       1       5.2    3056.0       3.0       1.0  2.0     264.0   \n",
       "4      3     1       0       8.8    3072.0       3.0       1.0  2.0     610.0   \n",
       "\n",
       "   Regionname  Propertycount  Price class  \n",
       "0           0         7570.0            1  \n",
       "1           0         2555.0            1  \n",
       "2           0         5420.0            1  \n",
       "3           0        11918.0            0  \n",
       "4           0        14577.0            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to drop mutiple values\n",
    "# 1) Removing all nan values and apply a standard one hot encoding to all the other values with catigorical values \n",
    "df3 = Training_data.copy()\n",
    "df3 = df3.drop('YearBuilt',axis=1)\n",
    "df3 = df3.dropna(axis = 0)\n",
    "df3 = df3.replace(to_replace= [\n",
    "    'Eastern Metropolitan',\n",
    "    'Northern Metropolitan',\n",
    "    'Southern Metropolitan',\n",
    "    'Western Metropolitan',\n",
    "    'South-Eastern Metropolitan',\n",
    "    'Eastern Victoria',\n",
    "    'Northern Victoria',\n",
    "    'Western Victoria'], \n",
    "    value = [0,0,0,0,0,1,1,1])\n",
    "df3 = df3.replace(to_replace= ['h','u','t'],\n",
    "                value= [1,0,2] )\n",
    "df3 = df3.replace(to_replace= ['S','SP','PI','VB','SA'], value= [0,1,2,3,4])\n",
    "df3 = df3.drop(['Lattitude','Longtitude'], axis=1)\n",
    "df3 = df3[df3.Landsize != 0.0]\n",
    "\n",
    "df3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = df3.iloc[:,:-1].copy()\n",
    "y3 = df3.iloc[:,-1].copy()\n",
    "X3_train,X3_test,y3_train,y3_test = train_test_split(X3,y3,test_size=0.3,random_state=100, stratify= y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8327074086719016 0.999268149882904\n"
     ]
    }
   ],
   "source": [
    "forest3 = RandomForestClassifier(criterion='gini',\n",
    "                                        n_estimators=500, \n",
    "                                        random_state= 100,\n",
    "                                        n_jobs=-1)\n",
    "forest3.fit(X3_train, y3_train)\n",
    "FTrain3 = forest3.score(X3_train, y3_train)\n",
    "FTest3  = forest3.score(X3_test, y3_test)\n",
    "\n",
    "print(FTest3,FTrain3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.84909\n",
      "Test accuracy: 0.80096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X3_train)\n",
    "\n",
    "X3_train_sc = sc.transform(X3_train)\n",
    "X3_test_sc = sc.transform(X3_test)\n",
    "\n",
    "svm = SVC(kernel='rbf', C=10, random_state=100)\n",
    "svm.fit(X3_train_sc, y3_train)\n",
    "\n",
    "print('Train accuracy: {0:.5f}'.format(svm.score(X3_train_sc, y3_train)))\n",
    "print('Test accuracy: {0:.5f}'.format(svm.score(X3_test_sc, y3_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.86961\n",
      "Test accuracy: 0.81137\n"
     ]
    }
   ],
   "source": [
    "sc1 = StandardScaler()\n",
    "sc1.fit(X_train)\n",
    "\n",
    "X_train_sc = sc1.transform(X_train)\n",
    "X_test_sc = sc1.transform(X_test)\n",
    "\n",
    "svm1 = SVC(kernel='rbf', C=10, random_state=100)\n",
    "svm1.fit(X_train_sc, y_train)\n",
    "\n",
    "print('Train accuracy: {0:.5f}'.format(svm1.score(X_train_sc, y_train)))\n",
    "print('Test accuracy: {0:.5f}'.format(svm1.score(X_test_sc, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_xtrain = X\n",
    "svc_ytrain = y\n",
    "svc_test = Test_data\n",
    "\n",
    "svc_test = svc_test.replace(to_replace= [\n",
    "    'Eastern Metropolitan',\n",
    "    'Northern Metropolitan',\n",
    "    'Southern Metropolitan',\n",
    "    'Western Metropolitan',\n",
    "    'South-Eastern Metropolitan',\n",
    "    'Eastern Victoria',\n",
    "    'Northern Victoria',\n",
    "    'Western Victoria'], \n",
    "    value = [0,0,0,0,0,1,1,1])\n",
    "svc_test = svc_test.replace(to_replace= ['h','u','t'],\n",
    "                value= [1,0,0] )\n",
    "svc_test = svc_test.replace(to_replace= ['S','SP','PI','VB','SA'], value= [1,1,0,0,0])\n",
    "svc_test = svc_test.drop(['Lattitude','Longtitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc3 = StandardScaler()\n",
    "sc3.fit(X)\n",
    "\n",
    "Train_sc = sc3.transform(X)\n",
    "Test_sc = sc3.transform(svc_test)\n",
    "\n",
    "svm2 = SVC(kernel='rbf', C=10, random_state=100)\n",
    "\n",
    "svm2.fit(Train_sc,y)\n",
    "\n",
    "\n",
    "svc_target_predictions = svm2.predict(Test_sc)\n",
    "output = pd.DataFrame({'index': svc_test.index,'Price class': svc_target_predictions})\n",
    "output.to_csv('CA4_submission_svc',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc1_xtrain = X3\n",
    "svc1_ytrain = y3\n",
    "svc1_test = Test_data\n",
    "svc1_test = svc1_test.drop('YearBuilt',axis=1)\n",
    "svc1_test = svc1_test.dropna(axis = 0)\n",
    "svc1_test = svc1_test.replace(to_replace= [\n",
    "    'Eastern Metropolitan',\n",
    "    'Northern Metropolitan',\n",
    "    'Southern Metropolitan',\n",
    "    'Western Metropolitan',\n",
    "    'South-Eastern Metropolitan',\n",
    "    'Eastern Victoria',\n",
    "    'Northern Victoria',\n",
    "    'Western Victoria'], \n",
    "    value = [0,0,0,0,0,1,1,1])\n",
    "svc1_test = svc1_test.replace(to_replace= ['h','u','t'],\n",
    "                value= [1,0,0])\n",
    "svc1_test = svc1_test.replace(to_replace= ['S','SP','PI','VB','SA'], value= [1,1,0,0,0])\n",
    "svc1_test = svc1_test.drop(['Lattitude','Longtitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc4 = StandardScaler()\n",
    "sc4.fit(svc1_xtrain)\n",
    "\n",
    "Train1_sc = sc4.transform(svc1_xtrain)\n",
    "Test1_sc = sc4.transform(svc1_test)\n",
    "\n",
    "svm3 = SVC(kernel='rbf', C=10, random_state=100)\n",
    "\n",
    "svm3.fit(Train1_sc,svc1_ytrain)\n",
    "\n",
    "\n",
    "svc1_target_predictions = svm3.predict(Test1_sc)\n",
    "output = pd.DataFrame({'index': svc1_test.index,'Price class': svc1_target_predictions})\n",
    "output.to_csv('CA4_submission1_svc',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "\n",
    "lr_pipe = make_pipeline(StandardScaler(),LogisticRegression(random_state=1))\n",
    "lr_pipe.fit(X3_train, y3_train)\n",
    "\n",
    "y3_pred = lr_pipe.predict(X3_test)\n",
    "print('Test Accuracy: %.3f' % lr_pipe.score(X3_test, y3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8079617357204627\n",
      "{'svc__C': 5.0, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline      import make_pipeline\n",
    "\n",
    "pipe_svc = make_pipeline(StandardScaler(), SVC(random_state=1))\n",
    "param_range  = np.linspace(5.0,10.0,5) # For regularization parameter C.\n",
    "param_range2 = [0.1, 1.0]         # For scaling parameter gamma og rbf-kernel.\n",
    "\n",
    "param_grid   = [{'svc__C': param_range, 'svc__kernel': ['linear']},\n",
    "                {'svc__C': param_range, 'svc__gamma': param_range2, 'svc__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svc, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X3_train, y3_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47e1008ba0e5545509d8bf1e77943f7a847bc077943055eae541f03bc518c428"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('inf200')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
